{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08c98da6-dd6a-45c3-9864-c682188a6294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8772282b-315b-472d-93bb-6a0d9d60064b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a3a4d0-b39c-41f1-9db9-5940b84f2060",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"standardcharges.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2246a3e3-1a2e-4dc3-9d3c-6eacce49ed30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hospital_name,last_updated_on,version,hospital_location,hospital_address,financial_aid_policy,license_number|NC,\"To the best of its knowledge and belief, the hospital has included all applicable standard charge information in accordance with the requirements of 45 CFR 180.50, and the information encoded is true, accurate, and complete as of the date indicated.\",general_contract_provisions\n",
      "The Charlotte Mecklenburg Hospital Authority,2024-12-01,2.0.0,Atrium Health Anson,\"2301 US Hwy 74 West, Wadesboro, NC 28170\",,H0082,TRUE,\n",
      "description,code|1,code|1|type,code|2,code|2|type,code|3,code|3|type,code|4,code|4|type,billing_class,setting,drug_unit_of_measurement,drug_type_of_measurement,modifiers,standard_charge|gross,standard_charge|discounted_cash,payer_name,plan_name,standard_charge|negotiated_dollar,standard_charge|negotiated_percentage,standard_charge|negotiated_algorithm,estimated_amount,standard_charge|methodology,standard_charge|min,standard_charge|max,additional_generic_notes,additional_payer_notes\n",
      "LENS IOL ACRYSOF IQ SA6AT5 1-PC 14.5 DIOPTER 3 CYLIND 6MM 13MM POST CHAMB TORIC ANT BICONVEX,258094,CDM,V2787,HCPCS,0276,RC,,,facility,inpatient,,,,495.00,247.50,Aetna,Broad Network,269.78,54.50,,,percent of total billed charges,151.47,470.25,,\n",
      "REAGENT ARCHITCT TRIGG SOLN 25TST 4X1 L C4100/CI16200/CI8200/I1000SR/I2000/I2000SR,116575,CDM,,,,,,,facility,inpatient,,,,16.29,8.15,Aetna,Broad Network,8.88,54.50,,,percent of total billed charges,4.98,15.48,,\n"
     ]
    }
   ],
   "source": [
    "with open(\".csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for i in range(5):\n",
    "        print(f.readline().strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b7538a",
   "metadata": {},
   "source": [
    "Loading data into smaller chunked files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31e1fc0-b66d-48de-b934-edcae77cf007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: charlotte_mecklenburg_hospital_cleaned_chunks//charlotte_mecklenburg_hospital_cleaned_part_0.csv (101895 rows)\n",
      "✅ Saved: charlotte_mecklenburg_hospital_cleaned_chunks//charlotte_mecklenburg_hospital_cleaned_part_1.csv (103316 rows)\n",
      "✅ Saved: charlotte_mecklenburg_hospital_cleaned_chunks//charlotte_mecklenburg_hospital_cleaned_part_2.csv (101199 rows)\n",
      "✅ Saved: charlotte_mecklenburg_hospital_cleaned_chunks//charlotte_mecklenburg_hospital_cleaned_part_3.csv (102613 rows)\n",
      "✅ Saved: charlotte_mecklenburg_hospital_cleaned_chunks//charlotte_mecklenburg_hospital_cleaned_part_4.csv (7995 rows)\n",
      "✅ All processing complete. Chunked files saved consistently in: charlotte_mecklenburg_hospital_cleaned_chunks/\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# === CONFIG ===\n",
    "input_file = \"standardcharges.csv\"\n",
    "output_dir = \"cleaned_chunks/\"\n",
    "header_row = 2\n",
    "rows_per_file = 100000  \n",
    "\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "columns_to_drop = [\n",
    "    \"code|3\", \"code|3|type\", \"code|4\", \"code|4|type\",\n",
    "    \"billing_class\", \"setting\", \"drug_unit_of_measurement\", \"drug_type_of_measurement\",\n",
    "    \"modifiers\", \"standard_charge|gross\", \"standard_charge|discounted_cash\",\n",
    "    \"standard_charge|negotiated_algorithm\", \"estimated_amount\", \"standard_charge|methodology\",\n",
    "    \"additional_generic_notes\", \"additional_payer_notes\"\n",
    "]\n",
    "\n",
    "\n",
    "columns_mapping = {\n",
    "    'description': 'DESCRIPTION',\n",
    "    'code|1': 'CODE',\n",
    "    'code|1|type': 'CODE_TYPE',\n",
    "    'payer_name': 'PAYER_NAME',\n",
    "    'plan_name': 'PLAN_NAME',\n",
    "    'standard_charge|negotiated_dollar': 'STANDARD_CHARGE_DOLLAR',\n",
    "    'standard_charge|min': 'MINIMUM_CHARGE',\n",
    "    'standard_charge|max': 'MAXIMUM_CHARGE'\n",
    "}\n",
    "\n",
    "\n",
    "def process_chunk(chunk):\n",
    "    \n",
    "    mask = (chunk[\"code|1|type\"] == \"CDM\") & (chunk[\"code|2|type\"] == \"CPT\")\n",
    "    chunk.loc[mask, \"code|1\"] = chunk.loc[mask, \"code|2\"]\n",
    "    chunk.loc[mask, \"code|1|type\"] = \"CPT\"\n",
    "\n",
    "    \n",
    "    chunk = chunk[chunk[\"code|1|type\"] == \"CPT\"]\n",
    "\n",
    "   \n",
    "    chunk = chunk.drop(columns=[\"code|2\", \"code|2|type\"], errors=\"ignore\")\n",
    "    chunk = chunk.drop(columns=[col for col in columns_to_drop if col in chunk.columns])\n",
    "\n",
    "    \n",
    "    dollar_col = \"standard_charge|negotiated_dollar\"\n",
    "    percent_col = \"standard_charge|negotiated_percentage\"\n",
    "    max_col = \"standard_charge|max\"\n",
    "\n",
    "    chunk[dollar_col] = pd.to_numeric(chunk[dollar_col], errors=\"coerce\")\n",
    "    chunk[percent_col] = pd.to_numeric(chunk[percent_col], errors=\"coerce\")\n",
    "    chunk[max_col] = pd.to_numeric(chunk[max_col], errors=\"coerce\")\n",
    "\n",
    "   \n",
    "    missing_both = chunk[dollar_col].isna() & chunk[percent_col].isna()\n",
    "    chunk = chunk[~missing_both]\n",
    "\n",
    "    \n",
    "    missing_dollar = chunk[dollar_col].isna() & chunk[percent_col].notna() & chunk[max_col].notna()\n",
    "    chunk.loc[missing_dollar, dollar_col] = (\n",
    "        chunk.loc[missing_dollar, percent_col] / 100 * chunk.loc[missing_dollar, max_col]\n",
    "    )\n",
    "\n",
    "   \n",
    "    chunk = chunk.drop(columns=[percent_col], errors=\"ignore\")\n",
    "\n",
    "   \n",
    "    chunk.rename(columns={k: v for k, v in columns_mapping.items() if k in chunk.columns}, inplace=True)\n",
    "\n",
    "    return chunk\n",
    "\n",
    "\n",
    "reader = pd.read_csv(input_file, header=header_row, chunksize=100000, low_memory=False)\n",
    "buffer = []\n",
    "total_rows = 0\n",
    "file_index = 0\n",
    "\n",
    "for chunk in reader:\n",
    "    cleaned = process_chunk(chunk)\n",
    "    if cleaned.empty:\n",
    "        continue\n",
    "\n",
    "    buffer.append(cleaned)\n",
    "    total_rows += len(cleaned)\n",
    "\n",
    "    if total_rows >= rows_per_file:\n",
    "        combined = pd.concat(buffer)\n",
    "\n",
    "        out_file = f\"{output_dir}/cleaned_part_{file_index}.csv\"\n",
    "        combined.to_csv(out_file, index=False)\n",
    "        print(f\"Saved: {out_file} ({len(combined)} rows)\")\n",
    "\n",
    "        buffer = []\n",
    "        total_rows = 0\n",
    "        file_index += 1\n",
    "\n",
    "\n",
    "if buffer:\n",
    "    combined = pd.concat(buffer)\n",
    "\n",
    "    out_file = f\"{output_dir}/cleaned_part_{file_index}.csv\"\n",
    "    combined.to_csv(out_file, index=False)\n",
    "    print(f\"Saved: {out_file} ({len(combined)} rows)\")\n",
    "\n",
    "print(\"All processing complete. Chunked files saved consistently in:\", output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a287039",
   "metadata": {},
   "source": [
    "combining chunked cleaned files to one file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e99b71b-ff72-41c8-8c97-69979f3cd269",
   "metadata": {},
   "source": [
    "Loading data into a single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cf8557-8b5f-4edf-bfc9-1ace588a7cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "input_file = \"standardcharges.csv\"\n",
    "output_dir = \"cleaned/\"\n",
    "output_file = os.path.join(output_dir, \"cleaned_all.csv\")\n",
    "header_row = 2\n",
    "chunk_size = 100000\n",
    "\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "columns_to_drop = [\n",
    "    \"code|3\", \"code|3|type\", \"code|4\", \"code|4|type\",\n",
    "    \"billing_class\", \"setting\", \"drug_unit_of_measurement\", \"drug_type_of_measurement\",\n",
    "    \"modifiers\", \"standard_charge|gross\", \"standard_charge|discounted_cash\",\n",
    "    \"standard_charge|negotiated_algorithm\", \"estimated_amount\", \"standard_charge|methodology\",\n",
    "    \"additional_generic_notes\", \"additional_payer_notes\"\n",
    "]\n",
    "\n",
    "# Final column name mapping\n",
    "columns_mapping = {\n",
    "    'description': 'DESCRIPTION',\n",
    "    'code|1': 'CODE',\n",
    "    'code|1|type': 'CODE_TYPE',\n",
    "    'payer_name': 'PAYER_NAME',\n",
    "    'plan_name': 'PLAN_NAME',\n",
    "    'standard_charge|negotiated_dollar': 'STANDARD_CHARGE_DOLLAR',\n",
    "    'standard_charge|min': 'MINIMUM_CHARGE',\n",
    "    'standard_charge|max': 'MAXIMUM_CHARGE',\n",
    "    'standard_charge|negotiated_percentage': 'STANDARD_CHARGE_PERCENTAGE'\n",
    "}\n",
    "\n",
    "# CHUNK PROCESSING\n",
    "def process_chunk(chunk, chunk_number):\n",
    "    \n",
    "    mask = (chunk[\"code|1|type\"] == \"CDM\") & (chunk[\"code|2|type\"] == \"CPT\")\n",
    "    chunk.loc[mask, \"code|1\"] = chunk.loc[mask, \"code|2\"]\n",
    "    chunk.loc[mask, \"code|1|type\"] = \"CPT\"\n",
    "\n",
    "    \n",
    "    chunk = chunk[chunk[\"code|1|type\"] == \"CPT\"]\n",
    "\n",
    "    \n",
    "    chunk = chunk.drop(columns=[\"code|2\", \"code|2|type\"], errors=\"ignore\")\n",
    "    chunk = chunk.drop(columns=[col for col in columns_to_drop if col in chunk.columns], errors=\"ignore\")\n",
    "\n",
    "    \n",
    "    dollar_col = \"standard_charge|negotiated_dollar\"\n",
    "    percent_col = \"standard_charge|negotiated_percentage\"\n",
    "    max_col = \"standard_charge|max\"\n",
    "\n",
    "    chunk[dollar_col] = pd.to_numeric(chunk[dollar_col], errors=\"coerce\")\n",
    "    chunk[percent_col] = pd.to_numeric(chunk[percent_col], errors=\"coerce\").fillna(0)\n",
    "    chunk[max_col] = pd.to_numeric(chunk[max_col], errors=\"coerce\")\n",
    "\n",
    "    \n",
    "    missing_dollar = chunk[dollar_col].isna() & chunk[max_col].notna()\n",
    "    chunk.loc[missing_dollar, dollar_col] = (\n",
    "        chunk.loc[missing_dollar, percent_col] / 100 * chunk.loc[missing_dollar, max_col]\n",
    "    )\n",
    "\n",
    "    \n",
    "    chunk.rename(columns={k: v for k, v in columns_mapping.items() if k in chunk.columns}, inplace=True)\n",
    "\n",
    "    print(f\"Processed chunk #{chunk_number} with {len(chunk)} rows.\")\n",
    "    return chunk\n",
    "\n",
    "# MAIN LOOP\n",
    "reader = pd.read_csv(input_file, header=header_row, chunksize=chunk_size, low_memory=False)\n",
    "all_cleaned = []\n",
    "chunk_number = 0\n",
    "\n",
    "for chunk in reader:\n",
    "    chunk_number += 1\n",
    "    cleaned = process_chunk(chunk, chunk_number)\n",
    "    if not cleaned.empty:\n",
    "        all_cleaned.append(cleaned)\n",
    "\n",
    "\n",
    "if all_cleaned:\n",
    "    final_df = pd.concat(all_cleaned, ignore_index=True)\n",
    "    final_df.to_csv(output_file, index=False)\n",
    "    print(f\"\\n All chunks processed. Final file saved as:\\n{output_file}\")\n",
    "    print(f\"Total rows saved: {len(final_df)}\")\n",
    "else:\n",
    "    print(\"No valid data to save.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0522c50e-7b6e-438c-82be-3086126a7d57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
